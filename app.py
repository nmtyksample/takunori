import streamlit as st
import pandas as pd
from geopy.distance import geodesic
import numpy as np
from sklearn.cluster import DBSCAN
import io
import requests
import urllib
import re

# ã‚¿ã‚¤ãƒˆãƒ«ã®è¨­å®š
st.title("ã‚ã„ã®ã‚Šã‚¿ã‚¯ã‚·ãƒ¼ã‚¢ãƒ—ãƒª_ã‚¿ã‚¯ã¨ã‚‚ğŸš•ğŸ‘«")

# å‡ºç™ºåœ°ç‚¹ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ¸‹è°·ã®NHKã®ä½æ‰€ã‚’è¨­å®š)
start_address = st.text_input("å‡ºç™ºåœ°ç‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="æ±äº¬éƒ½æ¸‹è°·åŒºç¥å—2-2-1 NHKæ”¾é€ã‚»ãƒ³ã‚¿ãƒ¼")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1åˆ—ç›®ã«åå‰ã€2åˆ—ç›®ã«ä½æ‰€ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

# GSI APIã‚’ä½¿ç”¨ã—ã¦ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def geocode_with_retry(address):
    makeUrl = "https://msearch.gsi.go.jp/address-search/AddressSearch?q="
    s_quote = urllib.parse.quote(address)
    response = requests.get(makeUrl + s_quote)
    if response.status_code == 200:
        data = response.json()
        if data:
            # ç·¯åº¦çµŒåº¦ã‚’å–å¾—
            coordinates = data[0]["geometry"]["coordinates"]
            return coordinates  # GSIã¯çµŒåº¦ã€ç·¯åº¦ã®é †ã§è¿”ã™ã“ã¨ãŒå¤šã„
        else:
            st.write(f"ä½æ‰€ '{address}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä½æ‰€ã®è¡¨è¨˜ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆä¾‹: 'ã€‡ã€‡å¸‚ã€‡ã€‡åŒº' ã®å½¢å¼ï¼‰ã€‚")
            return None, None
    else:
        st.write("APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚„APIã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None, None

if uploaded_file and start_address:
    # å‡ºç™ºåœ°ç‚¹ã®ç·¯åº¦çµŒåº¦ã‚’å–å¾—
    start_coords = geocode_with_retry(start_address)
    if not start_coords:
        st.error("å‡ºç™ºåœ°ç‚¹ã®ç·¯åº¦çµŒåº¦ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        df = pd.read_excel(uploaded_file)

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¨­å®š
        progress_bar = st.progress(0)
        total_steps = len(df)  # å…¨ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯ãƒ‡ãƒ¼ã‚¿è¡Œæ•°
        current_step = 0

        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä½æ‰€ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦å‡¦ç†
        people = []
        for index, row in df.iterrows():
            person = {
                "name": row.iloc[0],  
                "address": row.iloc[1]  
            }
            location = geocode_with_retry(person["address"])
            if location:
                person["coords"] = (location[1], location[0])
            else:
                st.write(f"Error: Could not geocode address for {person['name']} - {person['address']}")
                person["coords"] = None  # åº§æ¨™ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆ
            people.append(person)

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°
            current_step += 1
            progress_bar.progress(current_step / total_steps)

        # åº§æ¨™ãŒå–å¾—ã§ããŸäººã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
        people_with_coords = [person for person in people if person["coords"]]
        people_without_coords = [person for person in people if person["coords"] is None]

        # åº§æ¨™ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        coords = [person["coords"] for person in people_with_coords]

        if len(coords) < 2 and len(people_without_coords) == 0:
            st.error("ååˆ†ãªä½æ‰€ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # è·é›¢è¡Œåˆ—ã‚’è¨ˆç®—
            if len(coords) >= 2:
                dist_matrix = np.array([[geodesic(coord1, coord2).km for coord2 in coords] for coord1 in coords])

                # DBSCANã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
                epsilon = 2  # 2kmä»¥å†…ã®ç‚¹ã‚’åŒã˜ã‚¯ãƒ©ã‚¹ã‚¿ã¨è¦‹ãªã™
                dbscan = DBSCAN(eps=epsilon, min_samples=2, metric="precomputed")
                clusters = dbscan.fit_predict(dist_matrix)

                # ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘
                groups = {}
                for idx, cluster_id in enumerate(clusters):
                    if cluster_id != -1:  # -1ã¯ãƒã‚¤ã‚ºï¼ˆã©ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã‚‚å±ã•ãªã„ï¼‰
                        if cluster_id not in groups:
                            groups[cluster_id] = []
                        groups[cluster_id].append(people_with_coords[idx])

                # æ®‹ã£ãŸãƒã‚¤ã‚ºã®å‡¦ç†ï¼ˆå€‹åˆ¥ã‚¿ã‚¯ã‚·ãƒ¼ï¼‰
                noise = [people_with_coords[idx] for idx, cluster_id in enumerate(clusters) if cluster_id == -1]
                for person in noise:
                    groups[len(groups)] = [person]

            else:
                groups = {}  # åº§æ¨™ãŒãªã„å ´åˆã®å‡¦ç†

            # ä½æ‰€ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸäººã¯1äººã§1å°ã®ã‚¿ã‚¯ã‚·ãƒ¼ã‚’ä½¿ç”¨
            for person in people_without_coords:
                groups[len(groups)] = [person]

            # ã‚¿ã‚¯ã‚·ãƒ¼å‰²ã‚Šå½“ã¦
            taxis = []
            for group in groups.values():
                for i in range(0, len(group), 3):
                    taxis.append(group[i:i+3])  # æœ€å¤§3äººã¾ã§ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ã‚¿ã‚¯ã‚·ãƒ¼ã«å‰²ã‚Šå½“ã¦

            # çµæœã‚’è¡¨ç¤º
            result_data = []
            for i, taxi in enumerate(taxis):
                for passenger in taxi:
                    result_data.append({
                        "Taxi": i + 1,
                        "Name": passenger['name'],
                        "Address": passenger['address']
                    })

            # ä½æ‰€ã‹ã‚‰ã€ŒåŒºã€ã‚„ã€Œç”ºã€ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ï¼ˆã©ã®åœ°åŸŸã§ã‚‚å¯¾å¿œï¼‰
            def extract_area(address):
                match = re.search(r'(\S+åŒº|\S+ç”º|\S+å¸‚)', address)
                if match:
                    return match.group(1)
                return None

            # ä¸¦ã³æ›¿ãˆã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
            for passenger in result_data:
                passenger["Area"] = extract_area(passenger["Address"])

            # Taxiã”ã¨ã«ä¸¦ã³æ›¿ãˆï¼ˆã€ŒTaxiã€->ã€ŒAreaã€ï¼‰
            result_data_sorted = sorted(result_data, key=lambda x: (x["Taxi"], x["Area"]))

            # çµæœã‚’ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
            if st.button("çµæœã‚’ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                result_df = pd.DataFrame(result_data_sorted)
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    result_df.to_excel(writer, index=False, sheet_name='Taxis')
                st.download_button(label="Download Excel", data=output.getvalue(), file_name="taxi_results.xlsx")
